% !TEX root = developer.tex


\chapter{Discrete Event Simulation}
\label{chapter:des}
There are abundant tutorials on discrete event simulation around the web.
To understand the basic control flow of \sstmacro simulations,
you should consult Section 3.6, Discrete Event Simulation, in the user's manual.
For here, it suffices to simply understand that objects schedule events to run at a specific time.
When an event runs, it can create new events in the future.
A simulation driver gradually progresses time, running events when their time stamp is reached.
As discussed in the user's manual, we must be careful in the vocabulary.
\emph{Simulation time} or \emph{simulated time} is the predicted time discrete events are happening in the simulated hardware.
\emph{Wall time} or {wall clock time} is the time \sstmacro itself has been running.
There are a variety of classes the cooperate in driving the simulation, which we now describe.

\section{Event Managers}
\label{sec:eventManagers}
The driver for simulations is an event manager that provides the function

\begin{CppCode}
virtual void
schedule(timestamp start_time, event* event) = 0;
\end{CppCode}
This function must receive events and order them according to timestamp.
Two main types of data structures can be used, which we briefly describe below.

The event manager also needs to provide

\begin{CppCode}
virtual void
run() = 0;
\end{CppCode}

The termination condition can be:
\begin{itemize}
\item A termination timestamp is passed.  For example, a simulation might be specified to terminate after 100 simulation seconds. 
Any pending events after 100 seconds are ignored and the simulation exits.
\item The simulation runs out of events.  With nothing left to do, the simulation exits.
\end{itemize}

Events are stored in a queue (sorted by time)

\begin{CppCode}
namespace sstmac {

class event_queue_entry
{
 public:
  virtual void
  execute() = 0;

  ...
};
\end{CppCode}

The execute function is invoked by the \evmgr to run the underlying event.
There are generally two basic event types in \sstmacro, which we now introduce.

\subsection{Event Handlers}
\label{subsec:eventHandlers}
In most cases, the event is represented as a message sent to an object called an \evhandler at a specific simulation time.
In handling the message, the event handlers change their internal state and may cause more events
by scheduling new messages at other event handlers (or scheduling messages to itself) at a future time.
The workhorses for \sstmacro are therefore classes that inherit from \evhandler.
The only method that must be implemented is

\begin{CppCode}
void
handle(event* ev);
\end{CppCode}
The function is the common interface for numerous different operations from network injection to memory access to MPI operations.
In general, objects have two ``directions'' for the action - send or receive.
A NIC could ``handle'' a packet by injecting it into the network or ``handle'' a message by reporting up the network stack the message has arrived.
In most cases, the handled message must therefore carry with it some notion of directionality or final destination.
An event handler will therefore either process the message and delete the message, or, if that handler is not the final destination, forward it along.
Some event handlers will only ever receive, such as a handler representing a blocking \inlinecode{MPI_Recv} call.
Some event handlers will always receive and then send, such as network switches who are always intermediate steps between the start and endpoints of a network message.

In most cases, events are created by calling the function

\begin{CppCode}
void
schedule(const timestamp &t,
  event_handler* handler,
  event* ev);
\end{CppCode}

This then creates a class of type \inlinecode{event_queue_entry}, for which the execute function is

\begin{CppCode}
void
handler_event_queue_entry::execute()
{
  if (!canceled_) {
    handler_->handle(ev_to_deliver_);
  }
}
\end{CppCode}

Objects can inherit from \inlinecode{event_handler} to create new event handlers.
Alternatively (and probably the most common usage in the SST/macro core) is on-the-fly creation of event handlers through C++ templates.
The interface does not actually require using C++ templates.
The function \inlinecode{new_handler} defined in \inlineshell{event_callback.h} has the prototype:

\begin{CppCode}
template<class Cls, typename Fxn, class... Args>
event_handler*
new_handler(Cls* cls, Fxn fxn, const Args&... args);
\end{CppCode}

Here \inlinecode{Fxn} is a member function pointer.
When an \inlinecode{event* ev} is scheduled to the event handler, the member function pointer gets invoked:

\begin{CppCode}
(cls->*fxn)(ev, args...);
\end{CppCode}

For example, given a class \inlinecode{actor} with the member function \inlinecode{act}

\begin{CppCode}
void
actor::actor(event* ev, int ev_id){...}
\end{CppCode}
we can create an event handler

\begin{CppCode}
actor* a = ....;
event_handler* handler = new_handler(a, &actor::act, 42);
...
event* ev = ....;
schedule(time, handler, ev);
\end{CppCode}
When the time arrives for the event, the member function will be invoked

\begin{CppCode}
a->act(ev, 42);
\end{CppCode}

\subsection{Arbitrary Events}
In some cases, it can be inconvenient (and inefficient) to require every event to be funneled through an \evhandler type.
A generic macro for creating event queue entries from any class member function is provided in the file \inlineshell{event_callback.h} similar to the creation of C++ template event handlers above.
For example, the MPI server creates an event

\begin{CppCode}
mpi_queue_recv_request* req = next_request();
event_callback* ev = new_event(this, &mpi_queue::start_recv, req);
\end{CppCode}
The new event macro takes as first argument an object and second argument a member function pointer to be invoked when the event is run.
The remaining arguments are an arbitrary-length list of parameters of any type - they don't need to be messages. 
These parameters should match the member function prototype. 
For example, the prototype

\begin{CppCode}
void
mpi_queue::start_recv(mpi_queue_recv_request* req)
{
  ...
}
\end{CppCode}
takes a single \inlinecode{recv_request} object as input.
This eases the programming burden in two ways.
First, it avoids having to always create \evhandler types.
Without template events, you would have to create a new class the inherits from \evhandler that performs a single, desired action.
Second, it helps direct messages to the right place.  A single \evhandler might process many different types of events or objects.
If every event went to a single \inlinecode{handle} method, the handle method would need either a long if-else block or switch to sort messages.
The event would also need to be dynamic cast to the correct type.
By creating event functors, the message can be immediately directed to the correct type and correct action.

For generic events, one must ensure the event is scheduled to the same node and does not cross any network boundaries.
The event created must be run on the same logical process.

\subsection{Event Heap/Map}
\label{subsec:eventHeap}
The major distinction between different event containers is the data structured used.
The simplest data structure is an event heap or ordered event map.
The event manager needs to always be processing the minimum event time, which maps naturally onto a min-heap structure.
Insertion and removal are therefore log(N) operations where N is the number of currently scheduled events.
For most cases, the number and length of events is such that the min-heap is fine.

\section{Event Schedulers}
\label{sec:eventSchedulers}
The simulation is partitioned into objects that are capable of scheduling events.
Common examples of \evscheduler objects are nodes, NICs, memory systems, or the operating system.
In serial runs, an event scheduler is essentially just a wrapper for the \evmgr and the class is not strictly necessary.
There are two types of event scheduler: \inlinecode{event_component} and \inlinecode{event_subcomponent}.
In parallel simulation, though, the simulation must be partitioned into different scheduling units.
Scheduling units are then distributed amongst the parallel processes.
Components are the basic unit.  Currently only nodes and network switches are components.
All other devices (NIC, memory, OS) are subcomponents that must be linked to a parent component.
Even though components and subcomponents can both schedule events (both inherit from \evscheduler),
all subcomponents must belong to a component.  A subcomponent cannot be separated from its parent component during parallel simulation.



